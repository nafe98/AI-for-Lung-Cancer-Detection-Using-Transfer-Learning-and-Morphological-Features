{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4f74ed15",
   "metadata": {},
   "source": [
    "# Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0e52a0ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba4c963e",
   "metadata": {},
   "source": [
    "# List of Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4e89385d",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers = [\n",
    "    LogisticRegression()\n",
    "    \n",
    "]\n",
    "\n",
    "# Create a list to store results for each classifier\n",
    "results = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6fdc99d",
   "metadata": {},
   "source": [
    "# Define the number of folds for cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bfb261fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_splits = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a39ae5e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create StratifiedKFold cross-validator\n",
    "kf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "227ee6ec",
   "metadata": {},
   "source": [
    "# Loading Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9cd1dc72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to load and preprocess images\n",
    "def load_images_from_folder(folder):\n",
    "    images = []\n",
    "    labels = []\n",
    "    for subfolder_name in os.listdir(folder):\n",
    "        subfolder_path = os.path.join(folder, subfolder_name)\n",
    "        if os.path.isdir(subfolder_path):\n",
    "            label = subfolder_name  # Assuming folder names are class labels\n",
    "            for filename in os.listdir(subfolder_path):\n",
    "                img = cv2.imread(os.path.join(subfolder_path, filename))\n",
    "                if img is not None:\n",
    "                    img = cv2.resize(img, (224, 224))  # Adjust the size as needed\n",
    "                    images.append(img)\n",
    "                    labels.append(label)\n",
    "    return np.array(images), np.array(labels)\n",
    "\n",
    "# Load and preprocess your images\n",
    "X, y = load_images_from_folder('Dataset')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f77fadf6",
   "metadata": {},
   "source": [
    "# Data preprocessing: Normalize pixel values to the range [0, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3d699aa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X / 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b677e03",
   "metadata": {},
   "source": [
    "# Make Data 1D for compatability with Standard Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "431ba7fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_flat = X.reshape(X.shape[0], -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fb3af4f",
   "metadata": {},
   "source": [
    "# Create a DataFrame to store results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6241827f",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame(columns=['Classifier', 'Fold', 'Precision', 'Recall', 'F1 Score', 'Accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "817e083d",
   "metadata": {},
   "source": [
    "# Perform cross-validation for each classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b31ff6b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nafem\\anaconda3\\envs\\gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\nafem\\AppData\\Local\\Temp\\ipykernel_1476\\4154691716.py:34: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append({\n",
      "C:\\Users\\nafem\\anaconda3\\envs\\gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\nafem\\AppData\\Local\\Temp\\ipykernel_1476\\4154691716.py:34: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append({\n",
      "C:\\Users\\nafem\\anaconda3\\envs\\gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\nafem\\AppData\\Local\\Temp\\ipykernel_1476\\4154691716.py:34: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append({\n",
      "C:\\Users\\nafem\\anaconda3\\envs\\gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\nafem\\AppData\\Local\\Temp\\ipykernel_1476\\4154691716.py:34: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append({\n",
      "C:\\Users\\nafem\\anaconda3\\envs\\gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\nafem\\AppData\\Local\\Temp\\ipykernel_1476\\4154691716.py:34: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append({\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier: LogisticRegression, Fold: 1\n",
      "Precision: 0.9955\n",
      "Recall: 0.9955\n",
      "F1 Score: 0.9954\n",
      "Accuracy: 0.9955\n",
      "Fold Execution Time: 21.1267 seconds\n",
      "\n",
      "Classifier: LogisticRegression, Fold: 2\n",
      "Precision: 0.9879\n",
      "Recall: 0.9864\n",
      "F1 Score: 0.9866\n",
      "Accuracy: 0.9864\n",
      "Fold Execution Time: 24.2669 seconds\n",
      "\n",
      "Classifier: LogisticRegression, Fold: 3\n",
      "Precision: 0.9911\n",
      "Recall: 0.9909\n",
      "F1 Score: 0.9907\n",
      "Accuracy: 0.9909\n",
      "Fold Execution Time: 24.7978 seconds\n",
      "\n",
      "Classifier: LogisticRegression, Fold: 4\n",
      "Precision: 1.0000\n",
      "Recall: 1.0000\n",
      "F1 Score: 1.0000\n",
      "Accuracy: 1.0000\n",
      "Fold Execution Time: 23.8928 seconds\n",
      "\n",
      "Classifier: LogisticRegression, Fold: 5\n",
      "Precision: 0.9955\n",
      "Recall: 0.9954\n",
      "F1 Score: 0.9954\n",
      "Accuracy: 0.9954\n",
      "Fold Execution Time: 24.4986 seconds\n",
      "\n",
      "Classifier: LogisticRegression\n",
      "Average Precision: 0.9940\n",
      "Average Recall: 0.9936\n",
      "Average F1 Score: 0.9936\n",
      "Average Accuracy: 0.9936\n",
      "Average Fold Execution Time: 23.7166 seconds\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "results = []\n",
    "\n",
    "for clf in classifiers:\n",
    "    precision_scores = []\n",
    "    recall_scores = []\n",
    "    f1_scores = []\n",
    "    accuracy_scores = []\n",
    "    fold_times = []  # Store fold execution times\n",
    "    \n",
    "    for fold, (train_index, val_index) in enumerate(kf.split(X_flat, y), 1):\n",
    "        X_train, X_val = X_flat[train_index], X_flat[val_index]\n",
    "        y_train, y_val = y[train_index], y[val_index]\n",
    "\n",
    "        start_time = time.time()  # Record start time\n",
    "        clf.fit(X_train, y_train)\n",
    "        y_pred = clf.predict(X_val)\n",
    "\n",
    "        precision = precision_score(y_val, y_pred, average='weighted')\n",
    "        recall = recall_score(y_val, y_pred, average='weighted')\n",
    "        f1 = f1_score(y_val, y_pred, average='weighted')\n",
    "        accuracy = accuracy_score(y_val, y_pred)\n",
    "\n",
    "        precision_scores.append(precision)\n",
    "        recall_scores.append(recall)\n",
    "        f1_scores.append(f1)\n",
    "        accuracy_scores.append(accuracy)\n",
    "        \n",
    "        end_time = time.time()  # Record end time\n",
    "        fold_time = end_time - start_time  # Calculate fold execution time\n",
    "        fold_times.append(fold_time)\n",
    "\n",
    "        results_df = results_df.append({\n",
    "            'Classifier': clf.__class__.__name__,\n",
    "            'Fold': fold,\n",
    "            'Precision': precision,\n",
    "            'Recall': recall,\n",
    "            'F1 Score': f1,\n",
    "            'Accuracy': accuracy,\n",
    "            'Fold Time (s)': fold_time  # Store fold execution time\n",
    "        }, ignore_index=True)\n",
    "\n",
    "    avg_precision = np.mean(precision_scores)\n",
    "    avg_recall = np.mean(recall_scores)\n",
    "    avg_f1 = np.mean(f1_scores)\n",
    "    avg_accuracy = np.mean(accuracy_scores)\n",
    "    avg_fold_time = np.mean(fold_times)  # Calculate average fold execution time\n",
    "\n",
    "    results.append({\n",
    "        'Classifier': clf.__class__.__name__,\n",
    "        'Precision': avg_precision,\n",
    "        'Recall': avg_recall,\n",
    "        'F1 Score': avg_f1,\n",
    "        'Accuracy': avg_accuracy,\n",
    "        'Average Fold Time (s)': avg_fold_time  # Store average fold execution time\n",
    "    })\n",
    "\n",
    "# Print the results for each fold and the average result along with fold execution time\n",
    "for index, row in results_df.iterrows():\n",
    "    print(f\"Classifier: {row['Classifier']}, Fold: {row['Fold']}\")\n",
    "    print(f\"Precision: {row['Precision']:.4f}\")\n",
    "    print(f\"Recall: {row['Recall']:.4f}\")\n",
    "    print(f\"F1 Score: {row['F1 Score']:.4f}\")\n",
    "    print(f\"Accuracy: {row['Accuracy']:.4f}\")\n",
    "    print(f\"Fold Execution Time: {row['Fold Time (s)']:.4f} seconds\")  # Print fold execution time\n",
    "    print()\n",
    "\n",
    "# Print the average results along with average fold execution time\n",
    "for result in results:\n",
    "    print(f\"Classifier: {result['Classifier']}\")\n",
    "    print(f\"Average Precision: {result['Precision']:.4f}\")\n",
    "    print(f\"Average Recall: {result['Recall']:.4f}\")\n",
    "    print(f\"Average F1 Score: {result['F1 Score']:.4f}\")\n",
    "    print(f\"Average Accuracy: {result['Accuracy']:.4f}\")\n",
    "    print(f\"Average Fold Execution Time: {result['Average Fold Time (s)']:.4f} seconds\")  # Print average fold execution time\n",
    "    print()\n",
    "\n",
    "# Save results to an Excel file\n",
    "results_df.to_excel('Cross Validation ML.xlsx', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
